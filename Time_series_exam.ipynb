{
 "cells": [
  {
   "cell_type": "raw",
   "id": "coral-victory",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Time series exam\"\n",
    "author: \"Abel Garcia Penas\"\n",
    "output: rmarkdown::github_document\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-dating",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-grounds",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "library(forecast)\n",
    "library(ggplot2)\n",
    "library(xts)\n",
    "library(readxl)\n",
    "data <- read_excel(\"C:/Users/agpen/Documents/Data_Science/DSTI/Time_Series/Exam/Elec-train.xlsx\")\n",
    "rmse <- function(actual, pred) {\n",
    "  return(sqrt(mean((actual- pred)^2)))\n",
    "  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[4508:dim(data)[1],]\n",
    "data_train = data[1:4507,]\n",
    "names(data_train)<-c(\"Timestamp\", \"Power\", \"Temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-table",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 1. Series creation: Understanding the data\n",
    "## 1.1. Importing as xts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-texture",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_to_all_ratio = 0.8\n",
    "train_cut = as.integer(dim(data_train)[1]*train_to_all_ratio)\n",
    "\n",
    "elec_train=xts(data_train[1:train_cut,2:3], order.by=as.POSIXlt(data_train$Timestamp[1:train_cut], tz=\"\", format=\"%m/%d/%Y %H:%M\"), frequency = 24*4)\n",
    "periodicity(elec_train)\n",
    "elec_val=xts(tail(data_train[,2:3], dim(data_train)[1]-train_cut), order.by=as.POSIXlt(tail(data_train$Timestamp, dim(data_train)[1]-train_cut), tz=\"\", format=\"%m/%d/%Y %H:%M\"))\n",
    "\n",
    "names(elec_train) <- c(\"Power\", \"Temperature\")\n",
    "names(elec_val) <- c(\"Power\", \"Temperature\")\n",
    "autoplot(elec_train$'Power') + labs(title=\"Power consumption (kW)\") + labs(x=\"Date\") + labs(y=\"kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-kansas",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "xts objects are useful to perform a first evaluation in the series while keeping a time index fully informational in a \"%m/%d/%Y %H:%M\" format. By inspecting the series, a rational pattern can be seen:\n",
    "\n",
    "* A minimal power consumption from 23:00 to 8:00, matching classic sleeping time.\n",
    "* A high consumption between 8:00 and 17:00 aproximately, matching classic working hours.\n",
    "* An slight increase in the consumption around 17:00, following by a plateau with a smooth decrease until a sharp fall at 23:00. \n",
    "This suggest the use of a daily frequency for the creation of the time series (this parameter is critical for a later use of decompose or HoltWinters functions).\n",
    "\n",
    "### 1.1.2. Evaluating seasonal pattern\n",
    "One useful way of deeply stressing whether the seasonal pattern is well understood and captured, is to remove it by differentiation from the series and verify that the remaining series is stationary. Starting with the assumed daily seasonal pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-deviation",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "plot(diff(elec_train, lag=24*4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-hebrew",
   "metadata": {},
   "source": [
    "As it can be seen, most of the seasonal pattern is removed. However, there are two strange peaks taking place every week. These are probably the triplets Saturday-Sunday-Monday. It is also very interesting the weekday peaks on the 28-29 of January, happening inversely (weekday normal consumption, then one abnormally higher day and back to normal again): maybe some event like bank holidays or a general strike? Maybe some reparation works in the building requiring a lot of electricity?\n",
    "\n",
    "Anyway, what is clear is that the frequency needs to be refined to weekly to capture the sunday variation. This seasonal period is relevant when using decompose and HoltWinters methods, and needs to be hard-typed as the frequency parameter when defining the time series.\n",
    "\n",
    "## 1.2. As time series\n",
    "In this snippet the time series are defined, using a 80% of the data as the training set and 20% of the data as the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-hurricane",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_to_all_ratio = 0.8\n",
    "train_cut = as.integer(dim(data_train)[1]*train_to_all_ratio)\n",
    "freq=7*60*24/15\n",
    "ts_train = ts(data_train[1:train_cut,2], \n",
    "              start=c(2010,1),\n",
    "              frequency = 7*60*24/15)\n",
    "ts_temp = ts(data_train[1:train_cut,3], \n",
    "              start=c(2010,1),\n",
    "              frequency =7*60*24/15)\n",
    "starting_period=((length(ts_train)/freq)%%1)*freq+1\n",
    "ts_val = ts(tail(data_train[,2], dim(data_train)[1]-train_cut), \n",
    "              start=c(2015,starting_period),\n",
    "              frequency = 7*60*24/15)\n",
    "temp_val = ts(tail(data_train[,3], dim(data_train)[1]-train_cut), \n",
    "              start=c(2015,starting_period),\n",
    "              frequency = 7*60*24/15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-settle",
   "metadata": {},
   "source": [
    "Lastly, and now that the power and the temperature are cast into time series objects, we can try to understand whether the temperature is a relevant factor to be considered in the modeling...\n",
    "\n",
    "### 1.2.1 Influence of the temperature\n",
    "One visual way of gaining an intuition of whether the temperature drives some of the not-seasonal variation (specifically, differences between days) is to filter out the seasonal signal from both the temperature and the power series and compare the trend. To enable a visual comparison, both series are standardized before plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-muscle",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ts_train_weekly = ts(data_train[1:train_cut,2], \n",
    "              start=c(2010,1),\n",
    "              frequency = 60*24/15)\n",
    "ts_temp_weekly = ts(data_train[1:train_cut,3], \n",
    "              start=c(2010,1),\n",
    "              frequency =60*24/15)\n",
    "\n",
    "power_decomposed=decompose(ts_train_weekly, type=\"additive\")\n",
    "temp_decomposed=decompose(ts_temp_weekly, type=\"additive\")\n",
    "plot(scale(power_decomposed[[\"trend\"]], center = TRUE, scale=TRUE)) + lines(scale(temp_decomposed[[\"trend\"]], scale = TRUE, center = TRUE), col=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-interstate",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As it can be seen, the temperature drives indeed some of the variation, although there are a couple of peaks that are not coincident or only in one of the two series. Nevertheless, this graph suggests that including the temperature variable in the model might be interesting to increase its accuracy.\n",
    "\n",
    "# 2. Modelling based on past consumption\n",
    "In this section different models will be developed for the forecast of the power consumption based only on the past consumption.\n",
    "## 2.1. Modeling with exponential smoothing\n",
    "\n",
    "### 2.1.1 Additive seasonal Holt-Winters\n",
    "\n",
    "Starting with an additive seasonal Holt-Winters model, motivated by the fact that the time series is clearly (weekly) seasonal with an apparently constant oscillating amplitude. When the prediction for the validation period is compared against the actual validation time series, it can be appreciated a decent matching as shown in the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-insulation",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "LES=HoltWinters(ts_train, alpha=NULL, beta=NULL, gamma=NULL)\n",
    "LES_p<-predict(LES, n.ahead=902)\n",
    "\n",
    "plot(LES_p, col=2, xlab='Time period', ylab='Power (kW)')+lines(ts_val, col=3) + title(main='Additive seasonal Holt-Winters forecast vs validation time series')\n",
    "rmse(ts_val, LES_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-identity",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The RMSE for the validation interval was 13.99.\n",
    "\n",
    "## 2.2 ARIMA model\n",
    "Before removing the deterministic components of the time series (trend and seasonal component) it is useful to have a visual intuition of their morphology. This is shown in the graph below. As it can be seen and stated above, the season amplitude (\"vertical variation\") and period duration seem both of them constant.\n",
    "Interestingly, a slightly decreasing trend can be perceived (winter is going away?) and some periodicity can be perceived in the remainders (this will be addressed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoplot(decompose(ts_train, type=\"additive\"))+xlab('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-induction",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "To try to obtain an stationary time series the train sample was differentiated with a seasonal lag (weekly, 672 periods) and with a unit lag to remove the trend. A second seasonal differentiating was used to remove some significant autocorrelation remaining with a daily period. However, there is still a strong weekly autocorrelation that could not be removed, so it will be modelised in the SARIMA model by a order 1 seasonal MA.\n",
    "\n",
    "Just to toy around, the decomposition fo the differentiated series was plotted to gain a visual intuition of any trend or seasonality remaining. Only the weekly seasonal trend is still perceivable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-means",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ts_train %>% ggtsdisplay(lag.max = 700, main='Initial train set with ACF and PACF plots')\n",
    "ts_deseasonal <- ts_train %>% diff(lag=24*4*7, differences=2) \n",
    "\n",
    "ts_deseasonal <- ts_deseasonal %>% diff(differences=1) \n",
    "autoplot(decompose(ts_deseasonal, type=\"additive\"), main='Train series decompposed after differentiation')+xlab('Year')\n",
    "\n",
    "ts_deseasonal %>% ggtsdisplay(lag.max = 700, main='Differentiated train series')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-underwear",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Sadly the forecast package does not allow to include a seasonal component with a period higher than 350 in the SARIMA model due to computational reasons. Two workarounds will be used to tackle this issue. Still, just as an informative playaround an auto.arima was run in the differentiated train set. The Ljung-Box test shows that the residuals are significantly far from whiteness, as expected (ACF at period 672 is too remarkable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-circumstances",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "autofit_deseasonal = auto.arima(ts_deseasonal, seasonal=FALSE)\n",
    "summary(autofit_deseasonal)\n",
    "checkresiduals(autofit_deseasonal)\n",
    "autofit_deseasonal %>% residuals() %>% ggtsdisplay(lag.max=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-soldier",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The issue pointed out above is clearly identified by the creator and copyright holder of the forecast package https://robjhyndman.com/hyndsight/longseasonality/ . To workaround the incapacity of the package to handle long seasonal SARIMA models, the proposed strategy is to fit the seasonality of the time series with a Fourier series and use it as an exogenous regressor in a standard ARIMA model. This is the method followed hereunder. A gridsearch is carried out with a search range of (0-3) for each one of the parameters in the ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-thread",
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "for (p in 0:3) {\n",
    "  for (d in 0:3) {\n",
    "    for (q in 0:3){\n",
    "      fourier_fit = Arima(ts_train, order=c(p,d,q), xreg=fourier(ts_train, K=40))\n",
    "      fourier_p<-forecast(fourier_fit, h=902, xreg=fourier(ts_train, K=40, h=902))\n",
    "      error = rmse(ts_val, fourier_p$mean)\n",
    "      cat('The RMSE for an ARIMA (',p,',',d,',',q,') is:',error,'\\n')\n",
    "\n",
    "    }}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-improvement",
   "metadata": {},
   "source": [
    "Results are not shown above due to the time it takes to knit, but are presented in text below:\n",
    "\n",
    "The RMSE for an ARIMA ( 0 , 0 , 0 ) is: 16.88703 \n",
    "The RMSE for an ARIMA ( 0 , 0 , 1 ) is: 16.88549 \n",
    "The RMSE for an ARIMA ( 0 , 0 , 2 ) is: 16.8839 \n",
    "The RMSE for an ARIMA ( 0 , 0 , 3 ) is: 16.88223 \n",
    "The RMSE for an ARIMA ( 0 , 1 , 0 ) is: 17.77138 \n",
    "The RMSE for an ARIMA ( 0 , 1 , 1 ) is: 17.66255 \n",
    "The RMSE for an ARIMA ( 0 , 1 , 2 ) is: 16.89183 \n",
    "The RMSE for an ARIMA ( 0 , 1 , 3 ) is: 16.78554 \n",
    "The RMSE for an ARIMA ( 0 , 2 , 0 ) is: 596.7691 \n",
    "The RMSE for an ARIMA ( 0 , 2 , 1 ) is: 19.58943 \n",
    "The RMSE for an ARIMA ( 0 , 2 , 2 ) is: 19.18795 \n",
    "The RMSE for an ARIMA ( 0 , 2 , 3 ) is: 23.24842 \n",
    "The RMSE for an ARIMA ( 0 , 3 , 0 ) is: 375240.9 \n",
    "The RMSE for an ARIMA ( 0 , 3 , 1 ) is: 10579.75 \n",
    "The RMSE for an ARIMA ( 0 , 3 , 2 ) is: 39173.08 \n",
    "The RMSE for an ARIMA ( 0 , 3 , 3 ) is: 176883.1 \n",
    "The RMSE for an ARIMA ( 1 , 0 , 0 ) is: 16.87697 \n",
    "The RMSE for an ARIMA ( 1 , 0 , 1 ) is: 16.87747 \n",
    "The RMSE for an ARIMA ( 1 , 0 , 2 ) is: 16.87985 \n",
    "The RMSE for an ARIMA ( 1 , 0 , 3 ) is: 16.88048 \n",
    "The RMSE for an ARIMA ( 1 , 1 , 0 ) is: 17.73102 \n",
    "The RMSE for an ARIMA ( 1 , 1 , 1 ) is: 16.75994 \n",
    "The RMSE for an ARIMA ( 1 , 1 , 2 ) is: 16.76179 \n",
    "The RMSE for an ARIMA ( 1 , 1 , 3 ) is: 16.7648 \n",
    "The RMSE for an ARIMA ( 1 , 2 , 0 ) is: 943.3237 \n",
    "The RMSE for an ARIMA ( 1 , 2 , 1 ) is: 25.18599 \n",
    "The RMSE for an ARIMA ( 1 , 2 , 2 ) is: 76.7794 \n",
    "The RMSE for an ARIMA ( 1 , 2 , 3 ) is: 20.59331 \n",
    "The RMSE for an ARIMA ( 1 , 3 , 0 ) is: 242518.2 \n",
    "The RMSE for an ARIMA ( 1 , 3 , 1 ) is: 14260.64 \n",
    "The RMSE for an ARIMA ( 1 , 3 , 2 ) is: 113465.7 \n",
    "The RMSE for an ARIMA ( 1 , 3 , 3 ) is: 147749.5 \n",
    "The RMSE for an ARIMA ( 2 , 0 , 0 ) is: 16.87771 \n",
    "The RMSE for an ARIMA ( 2 , 0 , 1 ) is: 16.87641 \n",
    "The RMSE for an ARIMA ( 2 , 0 , 2 ) is: 16.88458 \n",
    "The RMSE for an ARIMA ( 2 , 0 , 3 ) is: 16.88443 \n",
    "The RMSE for an ARIMA ( 2 , 1 , 0 ) is: 17.64655 \n",
    "The RMSE for an ARIMA ( 2 , 1 , 1 ) is: 16.76325 \n",
    "The RMSE for an ARIMA ( 2 , 1 , 2 ) is: 16.75991 \n",
    "The RMSE for an ARIMA ( 2 , 1 , 3 ) is: 18.29587 \n",
    "The RMSE for an ARIMA ( 2 , 2 , 0 ) is: 969.7599 \n",
    "The RMSE for an ARIMA ( 2 , 2 , 1 ) is: 19.20146 \n",
    "The RMSE for an ARIMA ( 2 , 2 , 2 ) is: 24.40081 \n",
    "The RMSE for an ARIMA ( 2 , 2 , 3 ) is: 23.79382 \n",
    "The RMSE for an ARIMA ( 2 , 3 , 0 ) is: 622660.5 \n",
    "The RMSE for an ARIMA ( 2 , 3 , 1 ) is: 7659.549 \n",
    "The RMSE for an ARIMA ( 2 , 3 , 2 ) is: 22271.11 \n",
    "The RMSE for an ARIMA ( 2 , 3 , 3 ) is: 35991.83 \n",
    "The RMSE for an ARIMA ( 3 , 0 , 0 ) is: 16.88226 \n",
    "The RMSE for an ARIMA ( 3 , 0 , 1 ) is: 16.8848 \n",
    "The RMSE for an ARIMA ( 3 , 0 , 2 ) is: 16.78233 \n",
    "The RMSE for an ARIMA ( 3 , 0 , 3 ) is: 16.88464 \n",
    "The RMSE for an ARIMA ( 3 , 1 , 0 ) is: 17.47939 \n",
    "The RMSE for an ARIMA ( 3 , 1 , 1 ) is: 16.79463 \n",
    "The RMSE for an ARIMA ( 3 , 1 , 2 ) is: 18.11329 \n",
    "\n",
    "As it can be seen, the best result was obtained for a set of parameters of (1,1,1). This model is fitted on the training set and evaluated on the validation set. For the seasonal pattern, the order of the fourier transform can be viewed as an hyperparameter to optimized. As performed before for the ARIMA parameters, a for loop will be used to evaluate this hyperparameter by gridsearch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-arrangement",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for (fourier_order in 1:100){\n",
    "  fourier_fit = Arima(ts_train, order=c(1,1,1), xreg=fourier(ts_train, K=fourier_order))\n",
    "  fourier_p<-forecast(fourier_fit, h=902, xreg=fourier(ts_train, K=fourier_order, h=902))\n",
    "\n",
    "  fourier_rsme = rmse(ts_val, fourier_p$mean)\n",
    "    \n",
    "  cat('The RMSE for an ARIMA with fourier order ',fourier_order,' is:',fourier_rsme,'\\n')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-receiver",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As before, the results are presented as text because running the chuck takes too long while knitting:\n",
    "\n",
    "The RMSE for an ARIMA with fourier order  1  is: 60.82287 \n",
    "The RMSE for an ARIMA with fourier order  2  is: 62.33829 \n",
    "The RMSE for an ARIMA with fourier order  3  is: 62.57347 \n",
    "The RMSE for an ARIMA with fourier order  4  is: 62.87534 \n",
    "The RMSE for an ARIMA with fourier order  5  is: 64.50008 \n",
    "The RMSE for an ARIMA with fourier order  6  is: 64.45767 \n",
    "The RMSE for an ARIMA with fourier order  7  is: 44.89816 \n",
    "The RMSE for an ARIMA with fourier order  8  is: 46.71415 \n",
    "The RMSE for an ARIMA with fourier order  9  is: 48.42495 \n",
    "The RMSE for an ARIMA with fourier order  10  is: 49.00857 \n",
    "The RMSE for an ARIMA with fourier order  11  is: 50.70816 \n",
    "The RMSE for an ARIMA with fourier order  12  is: 52.15889 \n",
    "The RMSE for an ARIMA with fourier order  13  is: 53.01607 \n",
    "The RMSE for an ARIMA with fourier order  14  is: 22.09183 \n",
    "The RMSE for an ARIMA with fourier order  15  is: 21.96746 \n",
    "The RMSE for an ARIMA with fourier order  16  is: 21.89996 \n",
    "The RMSE for an ARIMA with fourier order  17  is: 21.87419 \n",
    "The RMSE for an ARIMA with fourier order  18  is: 21.83263 \n",
    "The RMSE for an ARIMA with fourier order  19  is: 21.6768 \n",
    "The RMSE for an ARIMA with fourier order  20  is: 21.6221 \n",
    "The RMSE for an ARIMA with fourier order  21  is: 19.50004 \n",
    "The RMSE for an ARIMA with fourier order  22  is: 19.48934 \n",
    "The RMSE for an ARIMA with fourier order  23  is: 19.43674 \n",
    "The RMSE for an ARIMA with fourier order  24  is: 19.35699 \n",
    "The RMSE for an ARIMA with fourier order  25  is: 19.26611 \n",
    "The RMSE for an ARIMA with fourier order  26  is: 19.22516 \n",
    "The RMSE for an ARIMA with fourier order  27  is: 19.21136 \n",
    "The RMSE for an ARIMA with fourier order  28  is: 17.42813 \n",
    "The RMSE for an ARIMA with fourier order  29  is: 17.36448 \n",
    "The RMSE for an ARIMA with fourier order  30  is: 17.29379 \n",
    "The RMSE for an ARIMA with fourier order  31  is: 17.26931 \n",
    "The RMSE for an ARIMA with fourier order  32  is: 17.22089 \n",
    "The RMSE for an ARIMA with fourier order  33  is: 17.20138 \n",
    "The RMSE for an ARIMA with fourier order  34  is: 17.21454 \n",
    "The RMSE for an ARIMA with fourier order  35  is: 17.00667 \n",
    "The RMSE for an ARIMA with fourier order  36  is: 16.95158 \n",
    "The RMSE for an ARIMA with fourier order  37  is: 16.91653 \n",
    "The RMSE for an ARIMA with fourier order  38  is: 16.87632 \n",
    "The RMSE for an ARIMA with fourier order  39  is: 16.82886 \n",
    "The RMSE for an ARIMA with fourier order  40  is: 16.75994 \n",
    "The RMSE for an ARIMA with fourier order  41  is: 16.73903 \n",
    "The RMSE for an ARIMA with fourier order  42  is: 16.376 \n",
    "The RMSE for an ARIMA with fourier order  43  is: 16.35976 \n",
    "The RMSE for an ARIMA with fourier order  44  is: 16.35097 \n",
    "The RMSE for an ARIMA with fourier order  45  is: 16.34966 \n",
    "The RMSE for an ARIMA with fourier order  46  is: 16.33365 \n",
    "The RMSE for an ARIMA with fourier order  47  is: 16.31225 \n",
    "The RMSE for an ARIMA with fourier order  48  is: 16.3193 \n",
    "The RMSE for an ARIMA with fourier order  49  is: 15.42456 \n",
    "The RMSE for an ARIMA with fourier order  50  is: 15.43435 \n",
    "The RMSE for an ARIMA with fourier order  51  is: 15.42916 \n",
    "The RMSE for an ARIMA with fourier order  52  is: 15.43051 \n",
    "The RMSE for an ARIMA with fourier order  53  is: 15.41862 \n",
    "The RMSE for an ARIMA with fourier order  54  is: 15.39425 \n",
    "The RMSE for an ARIMA with fourier order  55  is: 15.36348 \n",
    "The RMSE for an ARIMA with fourier order  56  is: 15.33897 \n",
    "The RMSE for an ARIMA with fourier order  57  is: 15.3065 \n",
    "The RMSE for an ARIMA with fourier order  58  is: 15.27847 \n",
    "The RMSE for an ARIMA with fourier order  59  is: 15.26554 \n",
    "The RMSE for an ARIMA with fourier order  60  is: 15.25559 \n",
    "The RMSE for an ARIMA with fourier order  61  is: 15.22965 \n",
    "The RMSE for an ARIMA with fourier order  62  is: 15.22358 \n",
    "The RMSE for an ARIMA with fourier order  63  is: 15.28628 \n",
    "The RMSE for an ARIMA with fourier order  64  is: 15.26668 \n",
    "The RMSE for an ARIMA with fourier order  65  is: 15.27593 \n",
    "The RMSE for an ARIMA with fourier order  66  is: 15.28811 \n",
    "The RMSE for an ARIMA with fourier order  67  is: 15.27892 \n",
    "The RMSE for an ARIMA with fourier order  68  is: 15.2853 \n",
    "The RMSE for an ARIMA with fourier order  69  is: 15.32915 \n",
    "The RMSE for an ARIMA with fourier order  70  is: 15.41649 \n",
    "The RMSE for an ARIMA with fourier order  71  is: 15.40514 \n",
    "The RMSE for an ARIMA with fourier order  72  is: 15.4137 \n",
    "The RMSE for an ARIMA with fourier order  73  is: 15.40356 \n",
    "The RMSE for an ARIMA with fourier order  74  is: 15.38304 \n",
    "The RMSE for an ARIMA with fourier order  75  is: 15.34771 \n",
    "The RMSE for an ARIMA with fourier order  76  is: 15.32581 \n",
    "The RMSE for an ARIMA with fourier order  77  is: 15.37724 \n",
    "The RMSE for an ARIMA with fourier order  78  is: 15.34707 \n",
    "The RMSE for an ARIMA with fourier order  79  is: 15.33272 \n",
    "The RMSE for an ARIMA with fourier order  80  is: 15.31757 \n",
    "The RMSE for an ARIMA with fourier order  81  is: 15.32375 \n",
    "The RMSE for an ARIMA with fourier order  82  is: 15.32546 \n",
    "The RMSE for an ARIMA with fourier order  83  is: 15.36219 \n",
    "The RMSE for an ARIMA with fourier order  84  is: 15.06636 \n",
    "The RMSE for an ARIMA with fourier order  85  is: 15.09422 \n",
    "The RMSE for an ARIMA with fourier order  86  is: 15.09553 \n",
    "The RMSE for an ARIMA with fourier order  87  is: 15.11723 \n",
    "The RMSE for an ARIMA with fourier order  88  is: 15.14095 \n",
    "The RMSE for an ARIMA with fourier order  89  is: 15.17668 \n",
    "The RMSE for an ARIMA with fourier order  90  is: 15.19314 \n",
    "The RMSE for an ARIMA with fourier order  91  is: 15.41263 \n",
    "The RMSE for an ARIMA with fourier order  92  is: 15.38278 \n",
    "The RMSE for an ARIMA with fourier order  93  is: 15.36476 \n",
    "The RMSE for an ARIMA with fourier order  94  is: 15.35196 \n",
    "The RMSE for an ARIMA with fourier order  95  is: 15.31078 \n",
    "The RMSE for an ARIMA with fourier order  96  is: 15.27228 \n",
    "The RMSE for an ARIMA with fourier order  97  is: 15.25702 \n",
    "The RMSE for an ARIMA with fourier order  98  is: 15.44931 \n",
    "The RMSE for an ARIMA with fourier order  99  is: 15.4239 \n",
    "The RMSE for an ARIMA with fourier order  100  is: 15.40881 \n",
    "\n",
    "As per the gridsearch above, the order employed will be K = 84.\n",
    "The graphs below show the agreement between the actual data and the model (fitted series for the training set and forecasted series for the validation set). \n",
    "The RMSE for this set up is 15.06."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-repair",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fourier_fit = Arima(ts_train, order=c(1,1,1), xreg=fourier(ts_train, K=84))\n",
    "fourier_p<-forecast(fourier_fit, h=902, xreg=fourier(ts_train, K=84, h=902))\n",
    "plot(fourier_p$fitted[1:672], col=2, type='l')+lines(ts_train[1:672], col=3)+title('Fitted vs training set - First week')\n",
    "\n",
    "plot(fourier_p$mean, col=2)+lines(ts_val, col=3)+title('Forecast vs validation set')\n",
    "\n",
    "fourier_fit %>% residuals() %>% ggtsdisplay()\n",
    "rmse(ts_val, fourier_p$mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-cattle",
   "metadata": {},
   "source": [
    "# 3. Modelling including temperature as covariate\n",
    "\n",
    "## 3.1. ARIMA model with Fourier transform\n",
    "\n",
    "The temperature might be as well a relevant covariate as discussed earlier in this report. It can be introduced in the model as an exogenous regressor, the same way the fourier transform was used above. In order to be consistent with the approach followed in the previous section, the seasonality of the ARIMA model will be modelled as a Fourier transform. Two exogenous variables will be introduced into the ARIMA model this time, the Fourier transform and the temperature.\n",
    "\n",
    "We first create the matrix with the exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "xreg_train = cbind(fourier(ts_train, K=84), ts_temp)\n",
    "xreg_val = cbind(fourier(ts_train, K=84, h=902), temp_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-eleven",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We follow an analogous procedure as done in the previous section. Again the plots for the agreement between the actual data and the model are presented.\n",
    "\n",
    "When introducing the temperature in the model the RMSE decreases from 15.06 to 15.01 (not a huge gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-nature",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fourier_temp_fit = Arima(ts_train, order=c(1,1,1), xreg = xreg_train)\n",
    "fourier_temp_p<-forecast(fourier_temp_fit, h=902, xreg = xreg_val)\n",
    "plot(fourier_temp_p$fitted[1:672], col=2, type='l')+lines(ts_train[1:672], col=3)+title('Fitted vs training set - First week')\n",
    "\n",
    "plot(fourier_temp_p$mean, col=2)+lines(ts_val, col=3)+title('Forecast vs validation set')\n",
    "\n",
    "fourier_temp_fit %>% residuals() %>% ggtsdisplay()\n",
    "rmse(ts_val, fourier_temp_p$mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-ceremony",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "checkresiduals(fourier_temp_fit, test='LB', plot=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-mention",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## 3.2. Linear regression\n",
    "\n",
    "In order to perform a linear regression with the trend and the season plus the temperature as covariate we need to explicitly reduce the frequency of the time series defined (tslm creates a covariate for each seasonal lag, and the dimensionality of a seasonal frequency of 672 periods (weekly) requires >30GB of RAM to fit the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-jewelry",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "ts_train_day = ts(data_train[1:train_cut,2], \n",
    "              start=c(2010,1),\n",
    "              frequency = 60*24/15)\n",
    "ts_temp_day = ts(data_train[1:train_cut,3], \n",
    "              start=c(2010,1),\n",
    "              frequency =60*24/15)\n",
    "\n",
    "ts_val_day = ts(tail(data_train[,2], dim(data_train)[1]-train_cut), \n",
    "              start=c(2047, 54),\n",
    "              frequency = 60*24/15)\n",
    "temp_val_day = ts(tail(data_train[,3], dim(data_train)[1]-train_cut), \n",
    "              start=c(2047, 54),\n",
    "              frequency = 60*24/15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-remains",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The linear regression model is fitted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-greek",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "linear_model_fit=tslm(ts_train_day~trend + season + ts_temp_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-testimony",
   "metadata": {},
   "source": [
    "As it can be seen in the residuals below and the Ljung-Box test, the hypothesis that the residuals have not autocorrelation can be rejected. Nevertheless, the RSME of this model is 19.67 so it will be discarded in favour of the ARIMA model with the Fourier transform as covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-startup",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "checkresiduals(linear_model_fit, test='LB', plot=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-initial",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "lin_model_p = forecast(linear_model_fit, xreg=temp_val_day, h=3605)\n",
    "rmse(ts_val, lin_model_p$mean[1:902])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-objective",
   "metadata": {},
   "source": [
    "## 3.3. Neural network\n",
    "\n",
    "As an alternative, a feed-forward neural network with one hidden layer will be trained with the training set, to evaluate its performance on the validation set. As it can be seen below, this kind of neural network does reasonably well in predicting the next day consumption, but leads to some unexpected and illogical behavior in the mid run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg=nnetar(ts_train_day,xreg=ts_temp_day)\n",
    "nn_cov_fit=forecast(nn_reg,h=902,xreg=temp_val_day)\n",
    "\n",
    "plot(nn_reg$fitted[1:672], col=2, type='l')+lines(ts_train_day[1:672], col=3)+title('Fitted vs training set - First week')\n",
    "\n",
    "plot(nn_cov_fit$mean, col=2) + lines(ts_val_day, col=3) + title('Forecast vs validation set')\n",
    "\n",
    "rmse(ts_val_day, nn_cov_fit$mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-coach",
   "metadata": {},
   "source": [
    "# 4.1 Next-day prediction\n",
    "\n",
    "Once the different models have been evaluated, the best performing model (basing on the RMSE criterion) will be chosen both for the case when the temperature is used for the forecast and for the case when that is not the case. This two models were:\n",
    "1. Only using the past consumption: Holt-Winters model with additive seasonal pattern. RSME: 13.99.\n",
    "2. Using the temperature as covariate: ARIMA model with fourier series as covariate. RSME: 15.01.\n",
    "\n",
    "The two models will be refitted with all the data available instead of the 80% employed for the training along this report. Both predictions will be exported into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_final_train = ts(data_train[,2], \n",
    "              start=c(2010,1),\n",
    "              frequency = 7*60*24/15)\n",
    "ts_final_temp = ts(data_train[,3], \n",
    "              start=c(2010,1),\n",
    "              frequency =7*60*24/15)\n",
    "LES_final=HoltWinters(ts_final_train, alpha=NULL, beta=NULL, gamma=NULL)\n",
    "LES_final_p<-predict(LES_final, n.ahead=96)\n",
    "# write.csv(as.data.frame(LES_final_p),\"Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-subject",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ts_temp_pred = ts(data_test[,3], \n",
    "              start=c(2016,475),\n",
    "              frequency =7*60*24/15)\n",
    "xreg_train_final = cbind(fourier(ts_final_train, K=84), ts_final_temp)\n",
    "xreg_pred_final = cbind(fourier(ts_final_train, K=84, h=96), ts_temp_pred)\n",
    "\n",
    "fourier_temp_fit = Arima(ts_final_train, order=c(1,1,1), xreg = xreg_train_final)\n",
    "fourier_final_p<-forecast(fourier_temp_fit, h=96, xreg = xreg_pred_final)\n",
    "# write.csv(as.data.frame(fourier_final_p),\"Predict_temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-biology",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
